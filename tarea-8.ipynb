{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Build and train a keras sequential model to classify digits form the mnist dataset. The model\n",
    "must have a hidden dense layer of 128 neurons with a relu activation function.\n",
    "2. Now build and train a keras functional model for the same problem. The model must have\n",
    "a hidden dense layer of 128 neurons with an activation function defined by the following\n",
    "function:\n",
    "activation(x) = ( 0 if x < 0, \n",
    "sin(x −π/2) + 1 if 0 ≤ x ≤ π/2,\n",
    "x −π/2 + 1 otherwise )\n",
    "3. Repeat the previous questions but now using PyTorch."
   ],
   "id": "dd98afd61b68d97d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Build and train a keras sequential model to classify digits form the mnist dataset. The model must have a hidden dense layer of 128 neurons with a relu activation function.",
   "id": "3cf9e58eee73862"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T20:04:00.535697Z",
     "start_time": "2024-04-24T20:03:59.822017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importa las bibliotecas necesarias\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Carga el conjunto de datos MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normaliza los datos de entrada\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Convierte las etiquetas a categorías\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Construye el modelo secuencial\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compila el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrena el modelo\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "\n",
    "# Evalúa el modelo\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)\n"
   ],
   "id": "8c079bdc61c3eba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.src.backend' has no attribute 'convert_to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 30\u001B[0m\n\u001B[1;32m     27\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Entrena el modelo\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# Evalúa el modelo\u001B[39;00m\n\u001B[1;32m     33\u001B[0m test_loss, test_acc \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(test_images, test_labels)\n",
      "File \u001B[0;32m~/miniconda3/envs/machine_learning2024/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/envs/machine_learning2024/lib/python3.9/site-packages/keras/src/utils/progbar.py:162\u001B[0m, in \u001B[0;36mProgbar.update\u001B[0;34m(self, current, values, finalize)\u001B[0m\n\u001B[1;32m    160\u001B[0m info \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[k], \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m--> 162\u001B[0m     avg \u001B[38;5;241m=\u001B[39m \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_numpy\u001B[49m(\n\u001B[1;32m    163\u001B[0m         backend\u001B[38;5;241m.\u001B[39mnumpy\u001B[38;5;241m.\u001B[39mmean(\n\u001B[1;32m    164\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[k][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[k][\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    165\u001B[0m         )\n\u001B[1;32m    166\u001B[0m     )\n\u001B[1;32m    167\u001B[0m     avg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(avg)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mabs\u001B[39m(avg) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1e-3\u001B[39m:\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'keras.src.backend' has no attribute 'convert_to_numpy'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T20:04:33.849160Z",
     "start_time": "2024-04-24T20:04:33.846261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ],
   "id": "6ad4c4261ac143ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "3.3.2\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T20:05:53.306678Z",
     "start_time": "2024-04-24T20:05:52.653049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importa las bibliotecas necesarias\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Carga el conjunto de datos MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normaliza los datos de entrada\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Convierte las etiquetas a categorías\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Construye el modelo secuencial\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compila el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrena el modelo\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "\n",
    "# Evalúa el modelo\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ],
   "id": "e156eb1111ec3056",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.src.backend' has no attribute 'convert_to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 30\u001B[0m\n\u001B[1;32m     27\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Entrena el modelo\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# Evalúa el modelo\u001B[39;00m\n\u001B[1;32m     33\u001B[0m test_loss, test_acc \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(test_images, test_labels)\n",
      "File \u001B[0;32m~/miniconda3/envs/machine_learning2024/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/envs/machine_learning2024/lib/python3.9/site-packages/keras/src/utils/progbar.py:162\u001B[0m, in \u001B[0;36mProgbar.update\u001B[0;34m(self, current, values, finalize)\u001B[0m\n\u001B[1;32m    160\u001B[0m info \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[k], \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m--> 162\u001B[0m     avg \u001B[38;5;241m=\u001B[39m \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_numpy\u001B[49m(\n\u001B[1;32m    163\u001B[0m         backend\u001B[38;5;241m.\u001B[39mnumpy\u001B[38;5;241m.\u001B[39mmean(\n\u001B[1;32m    164\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[k][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[k][\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    165\u001B[0m         )\n\u001B[1;32m    166\u001B[0m     )\n\u001B[1;32m    167\u001B[0m     avg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(avg)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mabs\u001B[39m(avg) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1e-3\u001B[39m:\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'keras.src.backend' has no attribute 'convert_to_numpy'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af6f8aec28c22db7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
