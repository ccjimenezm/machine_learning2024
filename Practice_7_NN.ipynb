{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJLmvD0bFE78"
   },
   "source": [
    "# Practice problems 7\n",
    "# [Machine Learning](https://dis.unal.edu.co/~fgonza/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zm1vQFIkFE8A"
   },
   "source": [
    "The following code implements a feed-forward neural network with one hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "nrvlVuyFFE8A",
    "ExecuteTime": {
     "end_time": "2024-04-17T21:19:13.731906Z",
     "start_time": "2024-04-17T21:19:13.420088Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def predict(w, x):\n",
    "    a = np.zeros((3,))\n",
    "    a[2] = relu(np.dot(x,w[6:8]) + w[8])\n",
    "    a[1] = relu(np.dot(x,w[3:5]) + w[5])\n",
    "    a[0] = sigmoid(np.dot(a[1:3], w[0:2]) + w[2])\n",
    "    return a[0]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJ2-dQdbFE8C"
   },
   "source": [
    "### 1.\n",
    "Find a weight vector such that the neural network calculates the negated XOR function:\n",
    "    \n",
    "$$f(x,y)=\\neg(x\\text{ xor }y)$$\n",
    "\n",
    "Use the following function to test your answer:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "ufaaQPqoFE8C",
    "outputId": "65747ebd-a682-485b-8f15-3db9f7be0051",
    "ExecuteTime": {
     "end_time": "2024-04-17T21:20:10.119582Z",
     "start_time": "2024-04-17T21:20:10.112919Z"
    }
   },
   "source": [
    "def test_prediction(X, Y, w):\n",
    "    epsilon = 0.001\n",
    "    for i, x in enumerate(X):\n",
    "        print (x, predict(w, x))\n",
    "        if np.abs(predict(w, x) - Y[i]) > epsilon:\n",
    "            raise Exception(\"Prediction error\")\n",
    "    return True\n",
    "\n",
    "w = np.array([-10, 30, 30, 20, 20, -10, 20, 20, -30])# you have to modify this vector\n",
    "\n",
    "X = [[0, 0],\n",
    " [0, 1],\n",
    " [1, 0],\n",
    " [1, 1]]\n",
    "Y = [1, 0, 0 ,1]\n",
    "test_prediction(X, Y, w)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 0.9999999999999065\n",
      "[0, 1] 3.975449735908647e-31\n",
      "[1, 0] 3.975449735908647e-31\n",
      "[1, 1] 0.9999999999999065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M61f9mjOFE8D"
   },
   "source": [
    "### 2.\n",
    "\n",
    "Suppose that we have a cross entropy loss function:\n",
    "\n",
    "$$L(w, x, y) = - y \\log f_w(x) - (1-y) \\log (1-f_w(x))$$\n",
    "\n",
    "where $f_w(x)$ corresponds to the prediction of the neural network from the  previous question."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "WlwtEDSoFE8E",
    "ExecuteTime": {
     "end_time": "2024-04-17T19:51:37.162822Z",
     "start_time": "2024-04-17T19:51:37.159764Z"
    }
   },
   "source": [
    "def loss(w, x, y):\n",
    "    return -y * np.log(predict(w, x)) -(1. - y) * np.log(1. - predict(w, x))"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7AIo_-7FE8E"
   },
   "source": [
    "Write a function that calculates the gradient of the loss with respect to the weights:\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial w} $$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "Y4pyiyyVFE8E",
    "ExecuteTime": {
     "end_time": "2024-04-17T20:19:21.620348Z",
     "start_time": "2024-04-17T20:19:21.616574Z"
    }
   },
   "source": [
    "def dL_dw(w, x, y):\n",
    "    # Inicializa un vector de ceros para el gradiente\n",
    "    delta = np.zeros(len(w))\n",
    "\n",
    "    # Calcula la salida de la red neuronal\n",
    "    a = predict(w, x)\n",
    "\n",
    "    # Calcula la derivada de la función de pérdida con respecto a la salida de la red neuronal\n",
    "    dL_da = -y / a + (1 - y) / (1 - a)\n",
    "\n",
    "    # Calcula las derivadas de la salida de la red neuronal con respecto a los pesos\n",
    "    da_dw = np.zeros(len(w))\n",
    "    for i in range(len(w)):\n",
    "        # Calcula la derivada de la función de activación con respecto al peso\n",
    "        if i < 2:  # pesos de la capa de salida\n",
    "            da_dw[i] = a * (1 - a)  # derivada de la función sigmoidal\n",
    "        else:  # pesos de la capa oculta\n",
    "            da_dw[i] = 1 if np.dot(x,w[6:8]) + w[8] > 0 else 0  # derivada de la función ReLU\n",
    "\n",
    "    # Usa la regla de la cadena para calcular el gradiente de la función de pérdida con respecto a los pesos\n",
    "    delta = dL_da * da_dw\n",
    "\n",
    "    return delta"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JDfuwzVFE8F"
   },
   "source": [
    "Use the following functions to test your code:"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tws = np.array([[-0.70032787,  0.05195189,  0.02322052,  1.4555916 ,  0.12168937,\n",
    "        -0.93580307, -0.58649814, -0.25847014, -0.11531032],\n",
    "       [ 1.11732048,  0.60225913,  0.05929297, -1.09018787,  2.33186956,\n",
    "         0.68248461, -0.16774443, -0.12996126,  0.31700533],\n",
    "       [ 0.80285183,  0.08585098,  1.62153749,  0.61251705,  0.18263732,\n",
    "         2.08412764, -0.2940164 , -0.72975557, -1.33828478],\n",
    "       [-0.74973286,  1.24623671,  0.63761743,  2.13714693,  0.90258674,\n",
    "         1.70238408, -2.60308453,  0.03070776,  2.34519973]])\n",
    "txs = np.array([[-0.96460511,  0.79790901],\n",
    "       [ 0.34546505,  0.92062212],\n",
    "       [-0.85750439,  0.50268203],\n",
    "       [ 0.69988938,  2.07328522]])\n",
    "tys = np.array([[ 0.66453404],\n",
    "       [-1.35012527],\n",
    "       [-0.7976646 ],\n",
    "       [ 0.57095802]])\n",
    "tls = np.array([[ 0.        , -0.03798627, -0.1555583 ,  0.        ,  0.        ,\n",
    "         0.        ,  0.0077955 , -0.00644834, -0.00808155],\n",
    "       [ 5.63408329,  0.32024725,  2.29715661,  0.88669136,  2.36292409,\n",
    "         2.56666012,  0.47794521,  1.27366556,  1.38348354],\n",
    "       [ 2.8850554 ,  0.        ,  1.74777687, -1.20325518,  0.70536637,\n",
    "         1.40320586,  0.        ,  0.        ,  0.        ],\n",
    "       [-2.48486794, -0.2877231 , -0.49016324,  0.25720339,  0.76191466,\n",
    "         0.36749148, -0.42753402, -1.26648581, -0.61085942]])\n",
    "\n",
    "def test_dL_dw():\n",
    "    num_tests = tws.shape[0]\n",
    "    epsilon = 0.0001\n",
    "    for i in range(num_tests):\n",
    "        tw = tws[i]\n",
    "        tx = txs[i]\n",
    "        ty = tys[i]\n",
    "        tl = tls[i]\n",
    "        if np.linalg.norm(dL_dw(tw, tx, ty) - tl) > epsilon:\n",
    "            raise Exception(\"dL_dw test failed!\")\n",
    "    return True\n",
    "\n",
    "test_dL_dw()"
   ],
   "metadata": {
    "id": "29TFtU9KMiyb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "outputId": "f626dcd8-247a-4921-fc2f-a852bd8ba41c",
    "ExecuteTime": {
     "end_time": "2024-04-17T20:19:24.852080Z",
     "start_time": "2024-04-17T20:19:24.825070Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/1bk8jf_n3f12dwr84x4lyc0dnc5f92/T/ipykernel_23233/3844363921.py:9: RuntimeWarning: divide by zero encountered in divide\n",
      "  dL_da = -y / a + (1 - y) / (1 - a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;31mTypeError\u001B[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 38\u001B[0m\n\u001B[1;32m     35\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdL_dw test failed!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m \u001B[43mtest_dL_dw\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[26], line 34\u001B[0m, in \u001B[0;36mtest_dL_dw\u001B[0;34m()\u001B[0m\n\u001B[1;32m     32\u001B[0m     ty \u001B[38;5;241m=\u001B[39m tys[i]\n\u001B[1;32m     33\u001B[0m     tl \u001B[38;5;241m=\u001B[39m tls[i]\n\u001B[0;32m---> 34\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(\u001B[43mdL_dw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mty\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m tl) \u001B[38;5;241m>\u001B[39m epsilon:\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdL_dw test failed!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[25], line 16\u001B[0m, in \u001B[0;36mdL_dw\u001B[0;34m(w, x, y)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(w)):\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;66;03m# Calcula la derivada de la función de activación con respecto al peso\u001B[39;00m\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m2\u001B[39m:  \u001B[38;5;66;03m# pesos de la capa de salida\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m         da_dw[i] \u001B[38;5;241m=\u001B[39m a \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m a)  \u001B[38;5;66;03m# derivada de la función sigmoidal\u001B[39;00m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# pesos de la capa oculta\u001B[39;00m\n\u001B[1;32m     18\u001B[0m         da_dw[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mdot(x,w[\u001B[38;5;241m6\u001B[39m:\u001B[38;5;241m8\u001B[39m]) \u001B[38;5;241m+\u001B[39m w[\u001B[38;5;241m8\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m  \u001B[38;5;66;03m# derivada de la función ReLU\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence."
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "3p-0h7W-URy0"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
